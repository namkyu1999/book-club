# Understanding Software Dynamics Ch.02

## 책 내용 정리 
2.4. 직선형 코드의 실수
- C 프로그램에서 반복문 없이 순차적인 코드로 add를 5000번 수행하는 경우: add 명령어를 측정하는 것이 아니다. 실제로는 아래 명령에 걸리는 시간을 측정하는 것과 같다.
  - 명령어 캐시나 메모리에서 1000개 이상의 순차적 명령어를 패치하는 비율
  - L1 캐시에서 sum 데이터를 불러오거나 저장하는 데 걸리는 시간
```c
sum+=1;
sum+=1;
sum+=1;
...
```

2.5 간단한 반복문, 반복문 오버헤드 실수, 컴파일러 최적화 실수
- [gcc 최적화 수준](https://gcc.gnu.org/onlinedocs/gnat_ugn/Optimization-Levels.html)
  - `gcc -O0 mystery0.cc -o mystery0`: 최적화 안 함(기본값); 최적화되지 않은 코드를 생성하지만 컴파일 시간이 가장 빠르다. 
    - `_rdtsc()`: 사이클 카운트를 읽을 수 있는 gcc 컴파일러 내장 함수; 32비트 명령어로 개발되었기 때문에 64비트로 만들어주기 위해 컴파일 시 3개의 명령어: `rdtsc`, `salq`, `orq`로 컴파일 된다.
  - `gcc -O2 mystery0.cc -o mystery0`: 완벽한 최적화; 고도로 최적화된 코드를 생성하며 컴파일 시간이 가장 느림.
    - 최적화 된 코드를 살펴보면, gcc optimizaer는 효율적으로 코드를 처리할 수 있도록 10억을 미리 계산하여 상수로 저장한다.
        ```
        rdtsc               # timestamp 카운터 읽기
        movq %rax, %rcx     # `새로 추가`: RAX 레지스터의 값을 RCX 레지스터로 이동
                            # (타임스탬프의 하위 32비트를 임시로 저장)
        salq $32, %rdx      # RDX 레지스터를 32비트 왼쪽으로 shift
        orq %rdx, %rcx      # `변경됨`: 이전 버전에서는 orq %rdx, %rax였는데
                            # RDX와 RCX를 OR 연산하여 64비트 타임스탬프를 생성

        rdtsc               # `새로 추가`: timestamp 카운터 읽기 (실행 시간 측정)
        pxor %xmm0, %xmm0   # `새로 추가`: XMM0 레지스터를 0으로 초기화 (??)
        movq stdout(%rip), %rdi # `새로 추가`: stdout 주소를 RDI 레지스터로 로드
        salq $32, %rdx      
        mov1 $1, %esi       # `새로 추가`: ESI 레지스터에 1 저장 (??) 
        orq %rdx, %rax      # 최종 64비트 타임스탬프를 생성
        ```
    - 출력 준비를 위한 명령어들이 추가 되었고, 반복문 관련 코드가 제거되었다.(루프 최적화가 적용됨)
    - 즉, gcc 컴파일러는 for loop가 단순히 1을 10억번 더하는 것으로 인식했고, 이 연산의 결과가 항상 10억이 된다는 것을 알았다 = 최적화 과정에서 루프를 실행하는 대신 결과를 미리 계산하여 상수로 저장한다.
    - 따라서 `sum+=1`을 제대로 측정할 수 없다. 최적화는 코드 실행 속도를 크게 향상시키지만, 원래 의도했던 개별 연산의 성능 측정을 불가능하게 만든다.

2.6 사용되지 않는 변수로 인한 실패
그래서 optimizer를 무력화 하기 위해서는 컴파일러가 모르는 상수를 사용해야 하고, 그럼에도 불구하고 gcc 컴파일러는 대부분 최적화 가능하다.
- 프로그램의 성능을 측정하려 할 때 처음 측정하려 했던 것과는 다른 것이 측정되는 일이 매부 빈번하게 발생한다.

2.7 향상된 반복문
- 반복문을 계속 유지하고 싶다면, sum 변수나 increment 변수를 colatile로 선언하여 전체 반복문을 수행하도록 컴파일에 강제화 할 수 있다. 이렇게 되면 컴파일러는 상수를 분석하여 최적화 하지 않고 항상 공유 메모리의 값을 직접 읽고 쓸 수 있다.
- 반복문 오버헤드를 줄이기 위해서는 루프를 unroll 하여 해결할 수 있다.
  - CPU 반복문 버퍼: CPU 내부의 작은 캐시로, 짧은 반복문의 명령어를 저장하는 공간이다. 반복문 명령어를 버퍼에 저장하고, 다음 반복 시 메모리 대신 버퍼에서 읽어오는 방식으로 반복문 실행 시 명령어 fetch를 줄여 성능을 향상시킬 수 있다. 
  - 루프 unrolling은 반복문 오버헤드를 줄이고 명령어 수준 병렬성을 높이지만, 과도하게 사용한다면 레지스터 부족을 유발할 수도 있다. 그래서 책에서는 반복문을 4~8번, 10회, 20회 정도로 풀어내는것이 적절하다고 함.
- 반복문 오버헤드를 측정하기 위해서는 N1번 반복하는 루프와 N2번 반복하는 루프의 실행 시간 차이를 계산한다.
- 측정 후 명령어 반복 1회 당 1.06사이클이 측정되더라도 실제로는 사용한 CPU 사이클은 정수값이다. 소숫값이 나온 이유는 CPU 코어로 전달된 인터럽트나, 동일한 물리 코어의 다름 프로그램의 하이퍼스레드 또는 OS 스케줄러에 의해 다른 프로그램과의 타임 슬라이싱 때문에 발생할 수 있다.
  - 따라서 성능 측정을 하는 경우, idle 장비에서 1-10msec 정도의 차이머 인터럽트 사이에서 측정하면 이러한 값을 최소화할 수 있다.
    - 만약 타이머 인터럽트 간격의 약 1/4 동안 실행한다 = 프로그램 실행 중 4번에 3번은 중간에 타이머 인터럽트가 발생하지 않는다. = 몇번 실행해보고 가장 빠른 값을 선택한다.
    - 측정할 반복문이 길고 타이머 인터럽트의 처리 시간이 짧은 경우 인터럽트로 인한 전체적인 왜곡은 매우 작을 수 있다.

2.8 의존적인 변수들
- 지연시간 = 명령어를 수행 후 후속 명령어가 결과를 사용할 수 있을 때까지의 시간
- 코드 2.5는 의존성이 없는 두 개의 sum 변수(sum과 sum2)를 사용하여 병렬성을 증가시킨다.
  - 이러한 경우, 병렬로 수행되기 때문에 평균 add의 실행 시간은 약 0.5사이클로 나타난다. 이는 어떤 add 명령어는 1 사이클이 걸리고, 다른 명령어는 동시에 중첩되어 실행되어 사실상 0 사이클로 측정되기 때문이다.

2.9 실제 실행 지연시간
- 컴파일러는 최적화 시 연산자를 재정렬 하기도 한다.
```c
volatile uint64_t incr0 = ...;
uint64_t prod = 1;
for(int i=0;i<kIterations;i+=4){
    prod*=incr0;
    prod*=incr1;
    prod*=incr2;
    prod*=incr3;
}
```
  - 실제로 `gcc -O2` 를 수행하면 아래와 같이 재정렬된다.
  ```c
  temp = ((incr0 * incr1) * incr2)*incr3; // 상수
  prod = prod*temp; // 의존성이 있는 변수
  ```

2.10 몇가지 추가 차이점
- 다시 연산을 피하기 위해 `gcc -fno-tree-reassoc` 플래그를 사용할 수 있다.
- 몇몇의 반복문은 결과가 부동소수점의 오버플로우(overflow)나 언더플로우(underflow)로 나타나 후속의 명령어가 이를 이용하는 데 직접적인 하드웨어 대신 10배 더 느린 방식으로 처리될 수도 있다. 

## 좋았던 부분
어떤 프로그램의 특정한 부분을 측정할 때 주의할 점을 자세하게 알려줘서 좋았다. 
